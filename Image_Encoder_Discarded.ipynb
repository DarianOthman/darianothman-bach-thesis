{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8867ae-f7fe-4774-a9b4-107f3f45fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "ndf=pd.read_csv('ndf.csv')\n",
    "# Find all words ending with '.jpg' in each row of text and associate them with the same value\n",
    "pic = []\n",
    "shortcode = []\n",
    "for i,rows in ndf.iterrows():\n",
    "    row_matches = re.findall(r'\\b\\w+\\.jpg\\b', ndf['pic'][i])\n",
    "    pic.extend(row_matches)\n",
    "    shortcode.extend([ndf['shortcode'][i]] * len(row_matches))\n",
    "\n",
    "# Create a DataFrame with the matches and associated values\n",
    "imgdf = pd.DataFrame({'pic': pic, 'value': shortcode})\n",
    "\n",
    "imgdf.to_csv('imgdf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63467b22-348b-4f46-932e-a65726087642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "imgdf=pd.read_csv('/workspace/persistent/imgdf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ed25c8-018c-4603-8769-eb38463c77db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_prefix(row):\n",
    "    prefix = '/workspace/persistent/img_resized/'\n",
    "    return prefix + row\n",
    "\n",
    "# Assuming you have a DataFrame named 'df'\n",
    "imgdf['pic'] = imgdf['pic'].apply(add_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "725f9bf8-f556-4a2a-8da1-40cdfa812e53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pic</th>\n",
       "      <th>shortcode</th>\n",
       "      <th>image_hidden</th>\n",
       "      <th>image_attention</th>\n",
       "      <th>image_representation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/workspace/persistent/img_resized/164431928821...</td>\n",
       "      <td>BbR09i0h1Ow</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/workspace/persistent/img_resized/164431930160...</td>\n",
       "      <td>BbR09i0h1Ow</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/workspace/persistent/img_resized/164431931264...</td>\n",
       "      <td>BbR09i0h1Ow</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/workspace/persistent/img_resized/164431932452...</td>\n",
       "      <td>BbR09i0h1Ow</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/workspace/persistent/img_resized/184385171323...</td>\n",
       "      <td>BmWrV0xlpUk</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369450</th>\n",
       "      <td>1369450</td>\n",
       "      <td>/workspace/persistent/img_resized/182635175151...</td>\n",
       "      <td>BlYgT3YHdv-</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369451</th>\n",
       "      <td>1369451</td>\n",
       "      <td>/workspace/persistent/img_resized/180665928368...</td>\n",
       "      <td>BkSlNpBBE9v</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369452</th>\n",
       "      <td>1369452</td>\n",
       "      <td>/workspace/persistent/img_resized/180665931722...</td>\n",
       "      <td>BkSlNpBBE9v</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369453</th>\n",
       "      <td>1369453</td>\n",
       "      <td>/workspace/persistent/img_resized/182773686690...</td>\n",
       "      <td>BldbP8mhNZz</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369454</th>\n",
       "      <td>1369454</td>\n",
       "      <td>/workspace/persistent/img_resized/192056304802...</td>\n",
       "      <td>BqnNeqmH51K</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1369455 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                                                pic  \\\n",
       "0                 0  /workspace/persistent/img_resized/164431928821...   \n",
       "1                 1  /workspace/persistent/img_resized/164431930160...   \n",
       "2                 2  /workspace/persistent/img_resized/164431931264...   \n",
       "3                 3  /workspace/persistent/img_resized/164431932452...   \n",
       "4                 4  /workspace/persistent/img_resized/184385171323...   \n",
       "...             ...                                                ...   \n",
       "1369450     1369450  /workspace/persistent/img_resized/182635175151...   \n",
       "1369451     1369451  /workspace/persistent/img_resized/180665928368...   \n",
       "1369452     1369452  /workspace/persistent/img_resized/180665931722...   \n",
       "1369453     1369453  /workspace/persistent/img_resized/182773686690...   \n",
       "1369454     1369454  /workspace/persistent/img_resized/192056304802...   \n",
       "\n",
       "           shortcode image_hidden image_attention image_representation  \n",
       "0        BbR09i0h1Ow         None            None                 None  \n",
       "1        BbR09i0h1Ow         None            None                 None  \n",
       "2        BbR09i0h1Ow         None            None                 None  \n",
       "3        BbR09i0h1Ow         None            None                 None  \n",
       "4        BmWrV0xlpUk         None            None                 None  \n",
       "...              ...          ...             ...                  ...  \n",
       "1369450  BlYgT3YHdv-         None            None                 None  \n",
       "1369451  BkSlNpBBE9v         None            None                 None  \n",
       "1369452  BkSlNpBBE9v         None            None                 None  \n",
       "1369453  BldbP8mhNZz         None            None                 None  \n",
       "1369454  BqnNeqmH51K         None            None                 None  \n",
       "\n",
       "[1369455 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1135cdb5-63fe-4487-8d65-9cff9974a12f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgdf['image_hidden']=None\n",
    "imgdf['image_attention']=None\n",
    "imgdf['image_representation']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b469a69a-ad53-4116-82ec-4a4f36fd1cd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Processing Images: 100%|█████████▉| 1368633/1369455 [6:58:23<00:15, 54.52it/s]  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import inception_v3\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device to CUDA if available, otherwise fall back to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load InceptionV3 model\n",
    "model = inception_v3(pretrained=True, aux_logits=True)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Create an empty list to store the feature vectors\n",
    "feature_vectors = []\n",
    "\n",
    "# Define the image loading and preprocessing function\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Iterate through the image files with tqdm\n",
    "with tqdm(total=len(imgdf), desc=\"Processing Images\") as progress_bar:\n",
    "    for _, row in imgdf.iterrows():\n",
    "        try:\n",
    "            # Load and preprocess the image\n",
    "            img = Image.open(row['pic'])\n",
    "            img = transform(img)\n",
    "            img = img.unsqueeze(0).to(device)  # Move image tensor to GPU\n",
    "\n",
    "            # Get the feature vector\n",
    "            with torch.no_grad():\n",
    "                features = model(img)\n",
    "                feature_vector = features.cpu()\n",
    "            imgdf.at[row, 'image_hidden'] = feature_vector.tolist()\n",
    "\n",
    "            # Update the progress bar\n",
    "            progress_bar.update(1)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e298105-5b9e-43fb-bb9c-06e8d85abf14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle_file_path = 'tensor.pkl'\n",
    "with open(pickle_file_path, 'wb') as file:\n",
    "    pickle.dump(concatenated_tensor, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cfc4689-31b6-40ef-9b5c-0f600cc91023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_file_path = 'tensor.pkl'\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    tensor = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "712c4304-e467-49f9-9122-f829ff0000fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_391/3163351653.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor = torch.tensor(tensor).cuda()\n",
      "Applying Attention: 100%|██████████| 1368633/1368633 [09:23<00:00, 2426.72it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the self-attention module\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=num_heads)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply self-attention\n",
    "        output, _ = self.attention(x, x, x)\n",
    "\n",
    "        return output.squeeze()\n",
    "\n",
    "# Define the parameters\n",
    "embedding_dim = 1000\n",
    "num_heads = 4\n",
    "\n",
    "# Create an instance of the self-attention module\n",
    "self_attention = SelfAttention(embedding_dim, num_heads).cuda()\n",
    "\n",
    "# Convert the given tensor to a PyTorch tensor and move to GPU\n",
    "tensor = torch.tensor(tensor).cuda()\n",
    "\n",
    "# Apply self-attention to all elements in the tensor\n",
    "feature_vectors = []\n",
    "with tqdm(total=len(imgdf), desc=\"Applying Attention\") as progress_bar:\n",
    "    for i,rows in imgdf.iterrows():\n",
    "        # Apply self-attention\n",
    "        output = self_attention(torch.tensor(imgdf['image_hidden'][i]).unsqueeze(0).to('cuda'))\n",
    "        with torch.no_grad():\n",
    "            output = output.cpu()\n",
    "        imgdf['image_attention'][i]=output.tolist()\n",
    "        progress_bar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "851011ae-afbe-444e-bf29-58a4ca501ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating the Image Score: 100%|██████████| 1368633/1368633 [00:14<00:00, 92610.02it/s] \n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=len(imgdf), desc=\"Calculating the Image Score\") as progress_bar:\n",
    "    for i,rows in imgdf.iterrows():\n",
    "        xi=torch.tensor(imgdf['image_hidden'][i]).unsqueeze(0).to('cuda')*torch.tensor(imgdf['image_attention'][i]).unsqueeze(0).to('cuda')\n",
    "        imgdf['image_representation'][i]=xi.tolist()\n",
    "        progress_bar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
